## 4. 预训练脚本构建

### GradScaler 的核心作用

**GradScaler 是专门为了让 float16（fp16）混合精度训练不“死掉”而发明的救命工具**。  
它通过“把 loss 临时放大几百倍到几万倍 → 算完梯度后再缩回来”，彻底解决 fp16 梯度下溢（变成 0）的问题，同时还能自动检测并跳过爆炸的梯度。

#### 为什么 fp16 训练必须用 GradScaler？

| 数据类型 | 能表示的最小正数（接近 0 的数） | 梯度典型大小 | 会发生什么？                     |
| -------- | ------------------------------- | ------------ | -------------------------------- |
| float32  | ≈ 1e-38                         | 1e-3 ~ 1e-6  | 完全没问题                       |
| float16  | ≈ 6e-5                          | 1e-3 ~ 1e-6  | 很多梯度直接变成 0 → 参数不更新  |
| bfloat16 | ≈ 1e-38（和 fp32 一样）         | 1e-3 ~ 1e-6  | 梯度不会下溢 → 不需要 GradScaler |

所以：  

- 用 **fp16** → **必须**用 GradScaler  
- 用 **bfloat16** 或 **fp32** → **不需要**用 GradScaler（甚至要主动禁用）

#### GradScaler 到底干了哪几件事？（完整流程）

```python
scaler = GradScaler()        # 初始化，初始 scale = 2**16 = 65536

for data, target in loader:
    optimizer.zero_grad()
    
    with autocast(dtype=torch.float16):     # 关键1：前向+反向用 fp16
        output = model(data)
        loss = criterion(output, target)
    
    scaler.scale(loss).backward()           # 关键2：loss 先放大 65536 倍
                                            # → 梯度也被放大 65536 倍，不下溢了
    
    scaler.step(optimizer)                  # 关键3~5：
                                            # 3. 先 unscale 梯度（除回 65536）
                                            # 4. 检查梯度里有无 inf/NaN
                                            # 5. 如果有 inf/NaN → 跳过 optimizer.step()
                                            #    如果没有 → 正常更新参数
    
    scaler.update()                         # 关键6：根据这次是否出现 inf/NaN
                                            # 自动增大或减小下一次的 scale 值
```

#### 实际效果对比（真实数字）

| 不使用 GradScaler（纯 fp16）   | 使用 GradScaler（推荐方式）       |
| ------------------------------ | --------------------------------- |
| 90% 的梯度直接变成 0           | 几乎所有梯度都保留下来            |
| loss 很快卡在 7.92（随机猜测） | loss 正常下降到 0.x               |
| 训练完全失败                   | 训练又快又稳（比 fp32 快 2~4 倍） |

#### 官方和所有大厂现在的标准写法（2024~2025）

```python
# 同时支持 fp32 / fp16 / bf16 自动切换
scaler = GradScaler(enabled=(args.dtype == 'float16'))   # 只有 fp16 时才启用

with torch.cuda.amp.autocast(enabled=(args.dtype != 'float32')):
    loss = model(input)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
optimizer.zero_grad()
```

#### 终极总结（记这一句话就够了）

**GradScaler 是 fp16 混合精度训练的“防死神器”**：  

- 没它 → fp16 训练 99% 的概率直接废掉  
- 有它 → 训练又快（显存省一半、速度快 2~4 倍）又稳  
- 用 bfloat16 或 fp32 → 完全不需要它（要主动关掉）

这也是为什么所有现代大模型（LLaMA、Mistral、Grok、SD3、DeepSeek 等）在用 fp16 训练时都必须加上这几行代码。



### “黑魔法”修复代码

这行代码：

```python
model._ddp_params_and_buffers_to_ignore = {"freqs_cos", "freqs_sin"}
```

是一段**非常典型但又容易被忽略的“黑魔法”修复代码**，专门用于解决 **LLaMA、Mistral、Grok、Qwen2、DeepSeek-V2 等现代大模型** 在使用 `DistributedDataParallel`（DDP）多卡训练时的一个**隐蔽但致命的 bug**。

#### 直接结论（先记答案）

这行代码的意思是：  
**告诉 PyTorch 的 DDP 模块：不要同步名为 `freqs_cos` 和 `freqs_sin` 的这两个 buffer！**

不加这行 → 多卡训练时会报错、挂掉、卡住、或者悄无声息地训练出错误模型  
加了这行 → 一切正常，训练顺利进行

#### 为什么这两个 buffer 不能被 DDP 同步？

我们来看看这两个名字是什么：

```python
self.freqs_cos: torch.Tensor   # 形状 [max_seq_len, rotary_dim]
self.freqs_sin: torch.Tensor   # 同样大小
```

它们是 **RoPE（Rotary Position Embedding）** 使用的预计算旋转角余弦/正弦表。

##### 关键特性（决定了它们不能被 DDP 同步）：

| 特性                             | 说明                                                         | 后果如果被同步会怎样 |
| -------------------------------- | ------------------------------------------------------------ | -------------------- |
| 完全由 `max_seq_len` 决定        | 训练开始前就根据最大长度算好，一次性生成                     | 没问题               |
| **所有 GPU 内容完全相同**        | 每张卡上的值都是一模一样的（deterministic）                  | 没必要同步，浪费通信 |
| **在 training 过程中会动态切片** | 每一步根据当前输入长度 `seq_len` 切 `freqs_cos[:seq_len]`    | 关键问题！           |
| **每个进程切片长度可能不同**     | 多卡时不同 rank 的 batch 里 seq_len 可能不同（尤其是动态 padding） | 致命！               |

#### 致命问题来了！

DDP 的默认行为是：

- 在每次 `optimizer.step()` 之前，所有 GPU 之间会 **allreduce 参数和 registered buffer**
- 包括 `freqs_cos` 和 `freqs_sin`

但训练时你会这样做（正常代码）：

```python
cos = self.freqs_cos[:seq_len]      # 每张卡 seq_len 可能不同！
sin = self.freqs_sin[:seq_len]
```

→ 不同 GPU 上 `freqs_cos` 和 `freqs_sin` 被切出了**不同长度**的 tensor  
→ DDP 认为它们“形状不一致” → 直接报错或挂掉

即使你用了 `register_buffer(..., persistent=False)` 也无效，因为 DDP 还是会尝试同步。

#### 官方解决方案就是这一行“黑魔法”：

```python
# 在模型构建完、DDP 包裹前加上这句
model._ddp_params_and_buffers_to_ignore = {"freqs_cos", "freqs_sin"}
```

或者更优雅的写法（新版 PyTorch 支持）：

```python
# 在注册 buffer 时就告诉它不要同步
model.register_buffer("freqs_cos", freqs_cos, persistent=False)
model.register_buffer("freqs_sin", freqs_sin, persistent=False)

# 然后加上这句（保险起见）
model._ddp_params_and_buffers_to_ignore = {"freqs_cos", "freqs_sin"}
```

#### 哪些模型必须加这行？

| 模型家族           | 是否需要这行代码 | 备注                     |
| ------------------ | ---------------- | ------------------------ |
| LLaMA-1/2/3        | 必须             | 官方代码都有             |
| Mistral / Mixtral  | 必须             | Hugging Face 实现加了    |
| Qwen2              | 必须             | 官方训练脚本有           |
| DeepSeek-V2        | 必须             | 官方明确写了这行         |
| Grok-1             | 很可能需要       | xAI 没开源，但大概率加了 |
| LLaMA-Factory 项目 | 自动加上         | 他们封装好了             |

#### 一句话总结

```python
model._ddp_params_and_buffers_to_ignore = {"freqs_cos", "freqs_sin"}
```

这行代码是 **2023~2025 年所有支持长序列 RoPE 的大模型多卡训练的必备补丁**，  
它的作用是：  
**“告诉 DDP：别管我这两个 RoPE 表，我自己保证它们在每张卡上一模一样，你别来同步添乱！”**

不加这行 → 多卡训练直接崩  
加了这行 → 完美运行，训练千亿模型都不怕

这就是为什么你在所有 SOTA 开源大模型的训练脚本里都能看到这行“神秘代码”。

### DataLoader

这行代码是 PyTorch 训练脚本里**最最最最标准的 DataLoader 写法**，几乎 100% 的现代大模型训练项目（LLaMA、Mistral、Qwen、Grok、DeepSeek、ChatGLM 等）都长这样：

```python
loader = DataLoader(
    train_ds,
    batch_sampler=batch_sampler,     # 关键！用了 batch_sampler
    num_workers=args.num_workers,
    pin_memory=True
)
```

下面把 `DataLoader` 的所有关键参数和这行代码的真实含义给你彻底讲透。

#### 1. DataLoader 的 3 种主要使用方式（你必须分清！）

| 方式                            | 写法                          | 适用场景                   | 是否能共存 |
| ------------------------------- | ----------------------------- | -------------------------- | ---------- |
| 方式1：最简单（单卡、小模型）   | `shuffle=True, batch_size=32` | debug、CV任务、小模型      | 不行       |
| 方式2：标准分布式（推荐）       | `sampler=xxx`                 | 多卡 DDP 训练              | 不行       |
| 方式3：终极专业版（大模型标配） | `batch_sampler=xxx`           | 断点续训 + 梯度累积 + 多卡 | 不行       |

这行代码用的是**方式3**，也就是当前最专业、最正确的写法！

#### 2. 每个参数详细解释（重点看加粗的）

| 参数                                          | 示例值                  | 含义 + 大模型实战经验                                        |
| --------------------------------------------- | ----------------------- | ------------------------------------------------------------ |
| `train_ds`                                    | `dataset`               | 你的 `torch.utils.data.Dataset` 对象                         |
| **`batch_sampler=batch_sampler`**             | `SkipBatchSampler(...)` | **最核心参数！**<br>一旦用了这个，就**不能**再用 `batch_size=`、`sampler=`、`shuffle=`、`drop_last=` 这四个参数了！它们会被完全忽略。<br>它一次性控制：采样顺序 + 批次大小 + 跳过哪些 batch（续训关键） |
| `num_workers=args.num_workers`                | 通常 4~16               | 子进程数，负责数据预处理（如解码、augmentation）<br>推荐值：**显卡数 × 4**（8卡就是 32）<br>太大吃内存，太小加载慢，建议 8~16 |
| `pin_memory=True`                             | `True`                  | **强烈建议永远打开！**<br>把数据提前拷贝到 CUDA 固定内存（pinned memory），`tensor.to(device)` 会变快 3~10 倍<br>对多卡训练提升巨大，几乎零成本 |
| 被禁用的参数（用了 batch_sampler 后不能写！） | —                       | `batch_size=`, `shuffle=`, `sampler=`, `drop_last=` → 写了也没用，会报警告或静默忽略 |

#### 3. 为什么大模型必须用 `batch_sampler=` 而不是 `batch_size=`？

因为要实现 **“断点续训时精确跳过已训练的 batch”**，只有 `batch_sampler` 能做到！

| 需求                      | 用 `batch_size=` 能不能实现？ | 用 `batch_sampler=`          |
| ------------------------- | ----------------------------- | ---------------------------- |
| 随机打乱                  | 可以                          | 可以                         |
| 多卡 DDP 正确划分数据     | 要配合 DistributedSampler     | 可以                         |
| 断点续训跳过前 N 个 batch | 完全不行！每次都从头          | 完美支持（SkipBatchSampler） |
| 梯度累积 + 续训对齐       | 错乱                          | 精确到 batch                 |

所以所有专业训练框架（LLaMA-Factory、Swift、xtuner、DeepSpeed、FSDP）都强制使用 `batch_sampler`。

#### 4. 完整标准写法（背下来就无敌）

```python
from torch.utils.data import DataLoader

# 1. 底层 sampler（单卡或多卡）
base_sampler = train_sampler or range(len(train_ds))   # train_sampler 通常是 DistributedSampler

# 2. 包装成能跳过 batch 的 batch_sampler（续训核心！）
batch_sampler = SkipBatchSampler(
    base_sampler,
    batch_size=args.batch_size,
    skip_batches=start_step * args.accumulation_steps   # 续训跳过已训练数据
)

# 3. 创建最专业的 DataLoader
loader = DataLoader(
    train_ds,
    batch_sampler=batch_sampler,   # 必须用这个
    num_workers=args.num_workers,  # 建议 8~32
    pin_memory=True,               # 必须打开！
    # 下面这些参数千万别写！会报错或无效
    # batch_size=xxx,      ← 错！
    # shuffle=True,        ← 错！
    # sampler=xxx,         ← 错！
    # drop_last=True,      ← 错！
)
```

#### 5. 一句总结（记住了你就 pro 了）

```python
loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=..., pin_memory=True)
```

这行代码的意思就是：

> “我是一个支持**断点续训 + 梯度累积 + 多卡 DDP** 的专业大模型训练 DataLoader，  
> 我用 `batch_sampler` 精确控制每一个 batch 的产生顺序，  
> 用多进程 + pin_memory 疯狂加速数据加载，  
> 你随便把我中断再恢复，我都能从上次的 exact batch 继续训练，绝不重复、绝不乱序！”

这就是为什么你看到所有 2024~2025 年的大模型训练脚本，DataLoader 都长这样 —— **因为这是目前唯一正确的方式**。

### 学习率（线性预热+余弦退火）

这是一个**超级经典、几乎所有大模型微调项目都在用的学习率调度公式**！

你看到的这个函数：

```python
def get_lr(current_step, total_steps, lr):
    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))
```

其实就是：

**线性预热（warmup）结束后，进入余弦退火（cosine decay）的学习率曲线**

它长得复杂，但本质是下面这张图：

![[image-1.png]]

#### 彻底拆解这个公式（你看完就彻底懂了）

```python
return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))
```

我们可以把它拆成两部分：

| 部分                             | 含义                             | 作用                                                |
| -------------------------------- | -------------------------------- | --------------------------------------------------- |
| `lr / 10`                        | **最小学习率**（最终衰减到的值） | 训练结束时，学习率不会到 0，而是停在初始 lr 的 1/10 |
| `0.5 * lr * (1 + math.cos(...))` | **余弦衰减的主干部分**           | 控制从最大 lr 平滑衰减到 0 的过程                   |

#### 为什么是 `1 + cos(...)`？

因为 `math.cos()` 的取值范围是 [-1, 1]：

| current_step        | cos(π × step/total) | 1 + cos(...) | 乘上 0.5*lr 后 |
| ------------------- | ------------------- | ------------ | -------------- |
| 0（开始）           | cos(0) = 1          | 2            | 1.0 × lr       |
| 中间                | cos(π/2) = 0        | 1            | 0.5 × lr       |
| total_steps（结束） | cos(π) = -1         | 0            | 0 × lr         |

所以整个函数的变化是：

```text
开始时： lr/10 + 1.0*lr = ~1.1*lr（略高于初始 lr）
结束时： lr/10 + 0*lr    = lr/10（最小学习率）
```

→ 这就是著名的 **“Cosine Decay with Hard Restart + Minimum LR”**，也被称为 **“余弦退火 + 10% 底噪”**

#### 它在实际项目中叫什么名字？

| 项目/框架                         | 他们怎么称呼这个学习率       | 备注         |
| --------------------------------- | ---------------------------- | ------------ |
| LLaMA-Factory、Swift、xtuner      | `cosine` 学习率（带 min_lr） | 默认就是这个 |
| Hugging Face Transformers         | `cosine_with_min_lr`         | 新版本支持   |
| DeepSpeed                         | `WarmupDecayLR` + `min_lr`   | 同款         |
| 论文《Attention is All You Need》 | 原始余弦（到 0）             | 没底噪       |
| **这个函数**                      | **最常见改进版余弦**         | 比原始更好！ |


#### 终极总结（背下来就 pro 了）

```python
return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))
```

这行代码的意思是：

> **“我用的是当前最强的学习率调度策略：  
> 先快速升到峰值，然后用余弦曲线优雅地衰减，  
> 但绝不衰减到 0，而是停在初始学习率的 1/10，  
> 让模型最后阶段还能‘微调呼吸’，收敛更稳更好！”**

这就是为什么你刷 LLaMA-Factory、Qwen、DeepSeek、Grok 等所有顶级微调项目，学习率调度函数都长这样 —— **因为它就是目前最好的**！

记住一句话：

> **“余弦退火 + 10% 最小学习率” = 2024~2025 年大模型微调的黄金学习率策略**  
> 你看到这个函数，就应该立刻说：“哦，专业选手在用最强的 lr scheduler！”

#### 线性预热

<font color=red>线性预热（Linear Warmup）到底是什么？  </font>

用最直白的一句话记住它：

**刚开始训练时，不要直接用你设置的大学习率（比如 5e-5），  
而是先从一个极小的学习率（比如 1e-8）开始，  
然后在前几千步里线性地、一口气把它“暖”到你设置的目标学习率。**

就像开车一样：你不会一脚油门直接飙到 200km/h，  

> 为什么几乎所有大模型训练都必须加 Warmup？（不加会死！）

| 不加 Warmup（直接用大 lr） | 加了 Warmup（前几千步慢慢涨） | 真实后果                                                     |
| -------------------------- | ----------------------------- | ------------------------------------------------------------ |
| 第一步梯度突然很大         | 梯度慢慢变大                  | loss 直接爆炸成 nan                                          |
| 参数更新太猛，冲过最优解   | 参数先“试探”着走              | 训练直接失败，卡在 nan                                       |
| 尤其在 Adam/AdamW 下更严重 | Adam 的动量还没积累好         | 所有大模型（BERT、LLaMA、Qwen、Grok…）不加 warmup 99% 直接死 |
| 分布式多卡更严重           | 多卡梯度同步还没稳定          | 更容易梯度爆炸                                               |

真实例子（你一定见过）：

```python
# 不加 warmup
lr = 5e-5
# 第1步就直接用 5e-5 → 死！

# 加了 warmup（前 1000 步从几乎 0 线性涨到 5e-5）
step 0     → lr ≈ 0
step 500   → lr ≈ 2.5e-5
step 1000  → lr = 5e-5   ← 之后进入正常调度（比如余弦衰减）
```

> 标准的线性 Warmup 公式（所有框架都长这样）

```python
if current_step < warmup_steps:
    # 线性从 0 涨到目标 lr
    lr = target_lr * (current_step / warmup_steps)
else:
    # warmup 结束后进入你的主调度（cosine、linear decay 等）
    lr = get_main_scheduler_lr(...)
```

> 各大框架实际默认的 warmup 步数（2025 年最新标准）

| 模型/框架             | 典型的 warmup 步数                            | 占比多少       |
| --------------------- | --------------------------------------------- | -------------- |
| LLaMA-3 8B 微调       | 1000 步                                       | 总步数的 3~10% |
| Qwen2、DeepSeek-V2    | 5% 的总 step（比如总 20000 步 → warmup 1000） | 5%             |
| LLaMA-Factory / Swift | 默认 3%                                       | 3%             |
| BERT 原文             | 10,000 步（当年数据少）                       | 约 1%          |
| 你的 4090 单卡微调    | 通常 200~1000 步就够                          | 看总步数       |

> 完整的“线性预热 + 余弦退火 + 最小 lr”代码（你现在看到的几乎所有项目都长这样）

```python
def get_lr(step, total_steps, warmup_steps, lr_max):
    if step < warmup_steps:
        # 线性预热阶段：从 0 → lr_max
        return lr_max * step / warmup_steps
    else:
        # 预热结束后：余弦退火 + 10% 最小 lr（就是你之前问的那个函数）
        progress = (step - warmup_steps) / (total_steps - warmup_steps)
        cosine = 0.5 * (1 + math.cos(math.pi * progress))
        return lr_max / 10 + cosine * lr_max * 0.5
```

### train_epoch 的参数

这行调用代码：

```python
train_epoch(epoch, loader, len(loader) + start_step + 1, start_step, wandb)
```

是**大模型断点续训（resume training）中最最最最最精妙的一行代码**，几乎所有专业训练框架（LLaMA-Factory、Swift、xtuner、DeepSpeed-Chat、OpenRLHF 等）都长得一模一样！

我们来把它彻底拆穿，保你看完立刻秒懂为什么这么写！

#### 先看函数定义（回顾）

```python
def train_epoch(epoch, loader, iters, start_step=0, wandb=None):
    # ...
    for step, batch in enumerate(loader, start=start_step + 1):
        # ...
```

关键参数：

- `iters`：告诉函数这个 epoch **总共应该有多少个 step**（用于日志、进度条、学习率计算）
- `enumerate(..., start=start_step + 1)`：让日志从 `start_step+1` 开始编号，**实现全局 step 连续**

#### 现在逐个解释你这行调用的每个参数

```python
train_epoch(
    epoch,                           # 第几个 epoch（比如 2）
    loader,                          # 当前 epoch 的 DataLoader（已经 SkipBatchSampler 跳过已训练数据）
    len(loader) + start_step + 1,    # ← 这才是神来之笔！
    start_step,                      # 从第几步开始续训（比如之前训练到 1500）
    wandb                            # 是否记录到 wandb
)
```

#### 核心：为什么 `iters = len(loader) + start_step + 1`？

我们用一个真实例子说明（假设你中断在第 1500 步）：

| 参数                  | 值                                                      | 含义                                                         |
| --------------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| `start_step`          | 1500                                                    | 上次训练到第 1500 步就停了                                   |
| 本次 loader 长度      | 1000                                                    | 本 epoch 还剩 1000 个 batch（因为前 1500 个被 SkipBatchSampler 跳过了） |
| 不写 + start_step + 1 | `len(loader) = 1000`                                    | 日志会显示：(1/1000), (2/1000)... 完全错误！                 |
| 正确写法              | `len(loader) + start_step + 1 = 1000 + 1500 + 1 = 2501` | 日志显示：(1501/2501), (1502/2501)... 完美连续！             |

#### 具体效果对比

| 不加 `+ start_step + 1`              | 正确加了 `+ start_step + 1`          |
| ------------------------------------ | ------------------------------------ |
| 日志：`Epoch:3 (1/1000) loss=2.1`    | 日志：`Epoch:3 (1501/2501) loss=2.1` |
| 学习率调度错乱（以为才训练 1000 步） | 学习率正确（知道已经训练 2500 步）   |
| wandb 曲线断层                       | wandb 曲线完美连续                   |
| 别人看日志一脸懵                     | 别人一看就知道是续训                 |

举个真实续训例子（数字说话）

假设你训练一个 3 epoch、每个 epoch 1000 步、初始 lr=5e-5 的模型：

| 情况                                                 | epoch | step               | current_global_step | total_global_steps | 当前真实 lr（正确）       | 如果 iters 写错成 len(loader)=400，会算出的 lr（错误）       |
| ---------------------------------------------------- | ----- | ------------------ | ------------------- | ------------------ | ------------------------- | ------------------------------------------------------------ |
| 从头训练                                             | 0     | 0                  | 0                   | 3000               | ≈0（warmup）              | 正确                                                         |
| 从头训练                                             | 2     | 999                | 2999                | 3000               | ≈5e-6（接近最小）         | 正确                                                         |
| **续训**（已训练完 2 个 epoch + 本 epoch 前 600 步） | 2     | 0（本轮实际第1步） | 2600                | 3000               | **≈8e-6**（余弦衰减中段） | 如果 `iters=len(loader)=400`，函数会算成：<br>`current_global_step = 2*400 + 0 = 800`<br>→ 错误地以为才训练 800 步 → lr 变成 **≈3e-5**（还很高！） |


**后果：**

- 正确情况：第 2600 步，学习率应该很小了（≈8e-6），模型在精细微调

- 错误情况：学习率突然从 8e-6 跳回 3e-5（相当于回到第 800 步时的学习率）

- 结果：**loss 暴涨 → 模型毁了 → 前面 2600 步白训**

#### 为什么必须写成 `len(loader) + start_step + 1`？

因为只有这样，才能让 `epoch * iters + step` 算出来是**真正的全局 step**：

#### 为什么是 `+ start_step + 1`，而不是 `+ start_step`？

因为：

- `enumerate(loader, start=start_step + 1)` → 日志从 `1501` 开始
- 总步数必须是 `2501`，这样进度条才是 `(1501/2501)` → `(2501/2501)`
- 如果写成 `len(loader) + start_step` = 2500，进度条就是 `(1501/2500)`，最后一步变成 `(2501/2500)` 越界！报错！

所以必须 `+1`！

#### 官方标准写法（所有大项目都这么写）

```python
# 恢复训练时
start_epoch = checkpoint['epoch']     # 比如 2
start_step  = checkpoint['step']      # 比如 1500（这个 epoch 已经训练了 1500 步）

# 构建跳过已训练 batch 的 loader
batch_sampler = SkipBatchSampler(..., skip_batches=start_step * accum_steps)
loader = DataLoader(..., batch_sampler=batch_sampler)

# 关键这行：让日志和学习率“假装”已经训练了 start_step 步
train_epoch(
    epoch=start_epoch,
    loader=loader,
    iters=len(loader) + start_step + 1,   # 必须 + start_step + 1
    start_step=start_step,
    wandb=wandb
)
```

#### 终极总结（背下来就无敌了）

```python
train_epoch(..., len(loader) + start_step + 1, start_step, ...)
```

这行调用的精髓是：

> **“虽然本次 DataLoader 只剩 1000 个 batch，  
> 但我已经训练了 1500 步了，  
> 所以你别给我显示 (1/1000)，  
> 要给我显示 (1501/2501)，  
> 学习率、日志、wandb 曲线都要接上，  
> 让全世界都看不出我断过！”**

### 实验结果

![image-20251215132336537](assets/4.Pretrain/image-20251215132336537.png)